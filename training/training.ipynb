{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNcl0PdnJWy5",
        "outputId": "8a0eb324-86cd-4473-aafe-ffd0c131f6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spotipy\n",
            "  Downloading spotipy-2.21.0-py3-none-any.whl (28 kB)\n",
            "Collecting requests>=2.25.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spotipy) (1.15.0)\n",
            "Collecting redis>=3.5.3\n",
            "  Downloading redis-4.4.0-py3-none-any.whl (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 17.9 MB/s \n",
            "\u001b[?25hCollecting urllib3>=1.26.0\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 42.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from redis>=3.5.3->spotipy) (4.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25.0->spotipy) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25.0->spotipy) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25.0->spotipy) (2022.9.24)\n",
            "Installing collected packages: urllib3, requests, redis, spotipy\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed redis-4.4.0 requests-2.28.1 spotipy-2.21.0 urllib3-1.26.13\n"
          ]
        }
      ],
      "source": [
        "# danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,liveness,valence,tempo\n",
        "\n",
        "!pip install spotipy\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import json\n",
        "import re\n",
        "import csv\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP7rBc2GUUlG",
        "outputId": "de246ef1-5a84-49d6-c4ed-bb0da5699482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-0.21.0\n"
          ]
        }
      ],
      "source": [
        "# load spotify api credentials from .env file\n",
        "\n",
        "# Upload the .env file to the colab, then you'll be able to use the spotify API (sp)\n",
        "\n",
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "CLIENT_ID = os.getenv(\"SPOTIFY_CLIENT_ID\")\n",
        "CLIENT_SECRET = os.getenv(\"SPOTIFY_CLIENT_SECRET\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhduHuCfT9KZ",
        "outputId": "a497aa05-4b7d-4564-dc19-8b186c9775da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spotipy.client.Spotify at 0x7fb626486f70>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Authentication - without user\n",
        "client_credentials_manager = SpotifyClientCredentials(client_id=CLIENT_ID, client_secret=CLIENT_SECRET)\n",
        "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)\n",
        "sp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "# DON'T NEED TO RUN CELLS BELOW THIS.\n",
        "########################################"
      ],
      "metadata": {
        "id": "5LKMREWWfpgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetPath = \"/content/subset\" \n",
        "\n",
        "# read json files of playlists.\n",
        "# returns array of playlists (playlists -> array of track ids)\n",
        "def get_playlists_from_json(fileNames):\n",
        "  playlists = [];\n",
        "\n",
        "  for fileName in fileNames:\n",
        "    f = open(datasetPath + \"/\" + fileName)\n",
        "    resp = json.load(f)\n",
        "    f.close()\n",
        "\n",
        "    for playlist in resp[\"playlists\"]:\n",
        "      track_ids = []\n",
        "      for track in playlist[\"tracks\"]:\n",
        "        track_ids.append(track[\"track_uri\"])\n",
        "      playlists.append(track_ids)\n",
        "  \n",
        "  return playlists"
      ],
      "metadata": {
        "id": "fO6THxYLOMBH",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "playlists = get_playlists_from_json([\"mpd.slice.0-999.json\"])\n",
        "len(playlists)"
      ],
      "metadata": {
        "id": "MbboxXPXPL4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly generate a triplet tuple (anchor, positive, negative)\n",
        "def random_triplet_generator():\n",
        "  random_playlist = random.sample(range(1000), 2)\n",
        "  playlist_len1 = len(playlists[random_playlist[0]])\n",
        "  playlist_len2 = len(playlists[random_playlist[1]])\n",
        "  random_indices = random.sample(range(playlist_len1), 2)\n",
        "  random_index_neg = random.randint(0, len(playlists[random_playlist[1]])-1)\n",
        "  random_song_anchor = random_indices[0]\n",
        "  random_song_positive = random_indices[1]\n",
        "\n",
        "
        "  anchor = playlists[random_playlist[0]][random_song_anchor]\n",
        "  \n",
        "  positive = playlists[random_playlist[0]][random_song_positive]\n",
        "\n",
        "  while True:\n",
        "    if playlists[random_playlist[1]][random_index_neg] not in playlists[random_playlist[0]]:\n",
        "      negative = playlists[random_playlist[1]][random_index_neg]\n",
        "      break\n",
        "    else:\n",
        "      random_index_neg = random.randint(0, len(playlists[random_playlist[1]])-1)\n",
        "  \n",
        "  return anchor, positive, negative"
      ],
      "metadata": {
        "id": "KoL5AJWFTle3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of pairs to randomly generate.\n",
        "NUM_PAIRS = 1000\n",
        "\n",
        "# Get feature vectors for the track id triplets.\n",
        "def data_to_feature_vector_triplets():\n",
        "  pairings = []\n",
        "  for i in range(NUM_PAIRS):\n",
        "    pairings.append(random_triplet_generator())\n",
        "\n",
        "  pairings_as_feature_vectors = []\n",
        "  for each_tuple in pairings:\n",
        "    resp = sp.audio_features(each_tuple)\n",
        "    resp = [list(x.values())[:11] for x in resp]\n",
        "    pairings_as_feature_vectors.append(resp)\n",
        "  return pairings, pairings_as_feature_vectors         "
      ],
      "metadata": {
        "id": "Bwrh1JvzZeFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairings, feature_vectors = data_to_feature_vector_triplets()"
      ],
      "metadata": {
        "id": "o36MttLGeOD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save ids & triplets to txt file.\n",
        "\n",
        "f = open(\"triplets.txt\", \"w\")\n",
        "for ids, features in zip(pairings, feature_vectors):\n",
        "  ids_str = \" \".join([id.split(\":\")[-1] for id in ids])\n",
        "  features_str = \" \".join([str(tuple(f)).replace(\" \", \"\") for f in features])\n",
        "  f.write(ids_str + \" \" + features_str + \"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "G-_DwBCuXwoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load triplets from triplets.txt file.\n",
        "\n",
        "import ast\n",
        "\n",
        "id_triplet_tuples = []\n",
        "features_triplet_tuples = []\n",
        "\n",
        "with open(\"triplets.txt\") as file:\n",
        "    for line in file:\n",
        "        arr = line.strip().split(\" \")\n",
        "        if len(arr) == 6:\n",
        "          id_triplet_tuples.append((arr[0], arr[1], arr[2]))\n",
        "          features_triplet_tuples.append((ast.literal_eval(arr[3]), ast.literal_eval(arr[4]), ast.literal_eval(arr[5])))\n",
        "\n",
        "print(id_triplet_tuples[:5])\n",
        "print(features_triplet_tuples[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTiZ425VdUyo",
        "outputId": "7761d871-d85f-4dd1-ead8-9cc92af0d20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('5CtI0qwDJkDQGwXD1H1cLb', '0SGkqnVQo9KPytSri1H6cF', '2ZdCrBA52bb4pIG3tOOZiQ'), ('4iYRa2btalAzPZoSYfROqF', '7KXjTSCq5nL1LoYtL7XAwS', '0CcQNd8CINkwQfe1RDtGV6'), ('7BVwi9cIzSc6tpyxsp47vJ', '7eSO4EeMnHvwpspyTav81c', '4DActPOAtak2m8meZeMt3B'), ('3JvKfv6T31zO0ini8iNItO', '6uhg6hQZkGtXF7pzxIpsCJ', '10M2Ex445zw585Ducldzkw'), ('0JEqGkvUiMTQmFY6sgL9kg', '047fCsbO4NdmwCBn8pcUXl', '6HMwkR2eZljupKeed8l0HZ')]\n",
            "[((0.694, 0.815, 2, -4.328, 1, 0.12, 0.229, 0, 0.0924, 0.813, 88.931), (0.78, 0.575, 1, -5.628, 0, 0.139, 0.106, 0, 0.129, 0.273, 81.502), (0.747, 0.606, 4, -5.286, 1, 0.172, 0.222, 0, 0.281, 0.2, 155.055)), ((0.568, 0.619, 1, -6.899, 1, 0.414, 0.138, 1.67e-06, 0.11, 0.293, 170.115), (0.908, 0.621, 1, -6.638, 0, 0.102, 0.000282, 5.39e-05, 0.0958, 0.421, 150.011), (0.779, 0.787, 10, -4.305, 0, 0.108, 0.0524, 0, 0.14, 0.708, 124.982)), ((0.595, 0.723, 7, -8.256, 1, 0.0349, 0.047, 0.0286, 0.0995, 0.272, 108.043), (0.444, 0.92, 1, -4.931, 0, 0.0646, 0.00125, 0.00563, 0.409, 0.774, 180.042), (0.57, 0.467, 9, -9.152, 0, 0.171, 0.0421, 0.00253, 0.125, 0.509, 111.58)), ((0.445, 0.537, 4, -8.532, 0, 0.04, 0.695, 1.65e-05, 0.0944, 0.131, 122.769), (0.658, 0.647, 3, -5.968, 1, 0.0584, 0.000855, 0.000226, 0.114, 0.878, 130.023), (0.607, 0.536, 10, -7.306, 1, 0.0305, 0.386, 0, 0.102, 0.434, 147.986)), ((0.649, 0.552, 1, -5.419, 0, 0.0292, 0.03, 6.47e-06, 0.111, 0.158, 89.969), (0.492, 0.26, 9, -17.341, 0, 0.0921, 0.646, 0.00178, 0.0705, 0.312, 111.519), (0.481, 0.885, 1, -6.238, 1, 0.303, 0.392, 0, 0.795, 0.616, 88.039))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class TripletLossLayer(Layer):\n",
        "  def __init__(self, alpha, **kwargs):\n",
        "    self.alpha=alpha\n",
        "    super(TripletLossLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'aplha':self.alpha\n",
        "    })\n",
        "    return config\n",
        "  \n",
        "  def triplet_loss(self, inputs):\n",
        "    a, p, n, = inputs\n",
        "    p_dist = K.sum(K.square(a-p), axis=-1)\n",
        "    n_dist = K.sum(K.square(a-n), axis=1)\n",
        "    return K.sum(K.maximum(p_dist-n_dist+self.alpha,0),axis=0)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    loss = self.triplet_loss(inputs)\n",
        "    self.add_loss(loss)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "oSkLO8r0gyXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Input for anchor, positive, and negative images\n",
        "in_a = Input(shape=(11, 1), name=\"song_a\")\n",
        "in_p = Input(shape=(11, 1), name=\"song_p\")\n",
        "in_n = Input(shape=(11, 1), name=\"song_n\")\n",
        "\n",
        "# create the base model\n",
        "base = layers.Dense(11)(in_a)\n",
        "flatten = layers.Flatten()(base)\n",
        "dense = layers.Dense(11, activation=\"relu\")(flatten) \n",
        "dense = layers.BatchNormalization()(dense)\n",
        "output = layers.Dense(11)(dense)\n",
        "\n",
        "embedding = Model(in_a, output, name=\"Embedding\")\n",
        "\n",
        "# Custom vector representation of each song\n",
        "emb_a, emb_p, emb_n = embedding(in_a), embedding(in_p), embedding(in_n)\n",
        "\n",
        "# Layer that computes the triplet loss from anchor, positive and negative embedding vectors\n",
        "triplet_loss_layer = TripletLossLayer(alpha=0.2, name='triplet_loss_layer')([emb_a, emb_p, emb_n])\n",
        "\n",
        "# Model that can be trained with anchor, positive, and negative feature vectors\n",
        "model = Model([in_a, in_p, in_n], triplet_loss_layer, name=\"model_2\") \n",
        "model.compile(loss=None, optimizer='adam')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CJTDDE6zg33V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80aa8d2-774d-4dc9-a59a-a68fd1dea0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " song_a (InputLayer)            [(None, 11, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " song_p (InputLayer)            [(None, 11, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " song_n (InputLayer)            [(None, 11, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " Embedding (Functional)         (None, 11)           1540        ['song_a[0][0]',                 \n",
            "                                                                  'song_p[0][0]',                 \n",
            "                                                                  'song_n[0][0]']                 \n",
            "                                                                                                  \n",
            " triplet_loss_layer (TripletLos  ()                  0           ['Embedding[0][0]',              \n",
            " sLayer)                                                          'Embedding[1][0]',              \n",
            "                                                                  'Embedding[2][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,540\n",
            "Trainable params: 1,518\n",
            "Non-trainable params: 22\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import convert_to_tensor\n",
        "\n",
        "# format the triplets to be compatible with the .fit()\n",
        "input_a = convert_to_tensor([i[0] for i in features_triplet_tuples])\n",
        "input_p = convert_to_tensor([i[1] for i in features_triplet_tuples])\n",
        "input_n = convert_to_tensor([i[2] for i in features_triplet_tuples])"
      ],
      "metadata": {
        "id": "GvwUidm0U-4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't run fit if you already have the weights.hdf5 file.\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Training the Model\n",
        "EPOCHS = 100 # Max number of epochs\n",
        "\n",
        "model.fit([input_a, input_p, input_n], \n",
        "    epochs = EPOCHS, \n",
        "    callbacks=[ModelCheckpoint(filepath='ckpts/epoch{epoch:03d}_loss{loss:.3f}.hdf5',\n",
        "                                monitor = 'loss',\n",
        "                                save_best_only = True,\n",
        "                                mode = 'auto',\n",
        "                                save_weights_only = True,\n",
        "                                verbose = 1),\n",
        "                EarlyStopping(monitor='loss',\n",
        "                              mode='auto',\n",
        "                              patience=10,\n",
        "                              verbose=True)])"
      ],
      "metadata": {
        "id": "77vmbmkng7qk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00c1253-ab72-41ae-ad1d-d16846196f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 76.7419\n",
            "Epoch 1: loss improved from inf to 73.14820, saving model to ckpts/epoch001_loss73.148.hdf5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 73.1482\n",
            "Epoch 2/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 42.9093\n",
            "Epoch 2: loss improved from 73.14820 to 39.69696, saving model to ckpts/epoch002_loss39.697.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 39.6970\n",
            "Epoch 3/100\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 28.5324\n",
            "Epoch 3: loss improved from 39.69696 to 25.57154, saving model to ckpts/epoch003_loss25.572.hdf5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 25.5715\n",
            "Epoch 4/100\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 17.6464\n",
            "Epoch 4: loss improved from 25.57154 to 17.02696, saving model to ckpts/epoch004_loss17.027.hdf5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 17.0270\n",
            "Epoch 5/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 13.1677\n",
            "Epoch 5: loss improved from 17.02696 to 12.86488, saving model to ckpts/epoch005_loss12.865.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 12.8649\n",
            "Epoch 6/100\n",
            "31/32 [============================>.] - ETA: 0s - loss: 11.0440\n",
            "Epoch 6: loss improved from 12.86488 to 10.88639, saving model to ckpts/epoch006_loss10.886.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 10.8864\n",
            "Epoch 7/100\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 9.2806\n",
            "Epoch 7: loss improved from 10.88639 to 8.95434, saving model to ckpts/epoch007_loss8.954.hdf5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 8.9543\n",
            "Epoch 8/100\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 7.6672\n",
            "Epoch 8: loss improved from 8.95434 to 7.32133, saving model to ckpts/epoch008_loss7.321.hdf5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 7.3213\n",
            "Epoch 9/100\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 6.4750\n",
            "Epoch 9: loss improved from 7.32133 to 6.31931, saving model to ckpts/epoch009_loss6.319.hdf5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 6.3193\n",
            "Epoch 10/100\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 6.3093\n",
            "Epoch 10: loss improved from 6.31931 to 6.16174, saving model to ckpts/epoch010_loss6.162.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 6.1617\n",
            "Epoch 11/100\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 6.0041\n",
            "Epoch 11: loss improved from 6.16174 to 5.83983, saving model to ckpts/epoch011_loss5.840.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 5.8398\n",
            "Epoch 12/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 5.8731\n",
            "Epoch 12: loss improved from 5.83983 to 5.77526, saving model to ckpts/epoch012_loss5.775.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 5.7753\n",
            "Epoch 13/100\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 5.7120\n",
            "Epoch 13: loss improved from 5.77526 to 5.38204, saving model to ckpts/epoch013_loss5.382.hdf5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 5.3820\n",
            "Epoch 14/100\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 5.1213\n",
            "Epoch 14: loss improved from 5.38204 to 5.10452, saving model to ckpts/epoch014_loss5.105.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 5.1045\n",
            "Epoch 15/100\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 5.6149\n",
            "Epoch 15: loss did not improve from 5.10452\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 5.5375\n",
            "Epoch 16/100\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 5.4819\n",
            "Epoch 16: loss did not improve from 5.10452\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 5.2707\n",
            "Epoch 17/100\n",
            "31/32 [============================>.] - ETA: 0s - loss: 5.1685\n",
            "Epoch 17: loss improved from 5.10452 to 5.03643, saving model to ckpts/epoch017_loss5.036.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 5.0364\n",
            "Epoch 18/100\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 5.5951\n",
            "Epoch 18: loss did not improve from 5.03643\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 5.4447\n",
            "Epoch 19/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 5.1608\n",
            "Epoch 19: loss did not improve from 5.03643\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 5.0600\n",
            "Epoch 20/100\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 5.2834\n",
            "Epoch 20: loss did not improve from 5.03643\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 5.2199\n",
            "Epoch 21/100\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 5.1348\n",
            "Epoch 21: loss improved from 5.03643 to 4.98388, saving model to ckpts/epoch021_loss4.984.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.9839\n",
            "Epoch 22/100\n",
            "31/32 [============================>.] - ETA: 0s - loss: 5.0090\n",
            "Epoch 22: loss improved from 4.98388 to 4.92003, saving model to ckpts/epoch022_loss4.920.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.9200\n",
            "Epoch 23/100\n",
            "17/32 [==============>...............] - ETA: 0s - loss: 4.5574\n",
            "Epoch 23: loss improved from 4.92003 to 4.71969, saving model to ckpts/epoch023_loss4.720.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.7197\n",
            "Epoch 24/100\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 5.0575\n",
            "Epoch 24: loss did not improve from 4.71969\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.8752\n",
            "Epoch 25/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 4.9482\n",
            "Epoch 25: loss did not improve from 4.71969\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.7734\n",
            "Epoch 26/100\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 4.5569\n",
            "Epoch 26: loss improved from 4.71969 to 4.49214, saving model to ckpts/epoch026_loss4.492.hdf5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.4921\n",
            "Epoch 27/100\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 4.9442\n",
            "Epoch 27: loss did not improve from 4.49214\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.7657\n",
            "Epoch 28/100\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 4.8522\n",
            "Epoch 28: loss did not improve from 4.49214\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.7758\n",
            "Epoch 29/100\n",
            "31/32 [============================>.] - ETA: 0s - loss: 4.6280\n",
            "Epoch 29: loss did not improve from 4.49214\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.5356\n",
            "Epoch 30/100\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 4.6183\n",
            "Epoch 30: loss did not improve from 4.49214\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 4.5586\n",
            "Epoch 31/100\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 4.7089\n",
            "Epoch 31: loss did not improve from 4.49214\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.5812\n",
            "Epoch 32/100\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 4.6674\n",
            "Epoch 32: loss did not improve from 4.49214\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.5490\n",
            "Epoch 33/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 4.8243\n",
            "Epoch 33: loss did not improve from 4.49214\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 4.7408\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - ETA: 0s - loss: 4.6975\n",
            "Epoch 34: loss did not improve from 4.49214\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.6975\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - ETA: 0s - loss: 4.4606\n",
            "Epoch 35: loss improved from 4.49214 to 4.46059, saving model to ckpts/epoch035_loss4.461.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4606\n",
            "Epoch 36/100\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 4.8331\n",
            "Epoch 36: loss did not improve from 4.46059\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.6695\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - ETA: 0s - loss: 4.4736\n",
            "Epoch 37: loss did not improve from 4.46059\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4736\n",
            "Epoch 38/100\n",
            "31/32 [============================>.] - ETA: 0s - loss: 4.7236\n",
            "Epoch 38: loss did not improve from 4.46059\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.6344\n",
            "Epoch 39/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 4.5292\n",
            "Epoch 39: loss improved from 4.46059 to 4.41711, saving model to ckpts/epoch039_loss4.417.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4171\n",
            "Epoch 40/100\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 4.5486\n",
            "Epoch 40: loss did not improve from 4.41711\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4475\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - ETA: 0s - loss: 4.2768\n",
            "Epoch 41: loss improved from 4.41711 to 4.27679, saving model to ckpts/epoch041_loss4.277.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.2768\n",
            "Epoch 42/100\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 4.6964\n",
            "Epoch 42: loss did not improve from 4.27679\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.5383\n",
            "Epoch 43/100\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 4.7150\n",
            "Epoch 43: loss did not improve from 4.27679\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.6336\n",
            "Epoch 44/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 4.7915\n",
            "Epoch 44: loss did not improve from 4.27679\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.7530\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - ETA: 0s - loss: 4.4466\n",
            "Epoch 45: loss did not improve from 4.27679\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4466\n",
            "Epoch 46/100\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 4.4547\n",
            "Epoch 46: loss did not improve from 4.27679\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.5605\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - ETA: 0s - loss: 4.4783\n",
            "Epoch 47: loss did not improve from 4.27679\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4783\n",
            "Epoch 48/100\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 4.5021\n",
            "Epoch 48: loss did not improve from 4.27679\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4108\n",
            "Epoch 49/100\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 4.3456\n",
            "Epoch 49: loss did not improve from 4.27679\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.3096\n",
            "Epoch 50/100\n",
            "31/32 [============================>.] - ETA: 0s - loss: 4.3869\n",
            "Epoch 50: loss improved from 4.27679 to 4.27328, saving model to ckpts/epoch050_loss4.273.hdf5\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.2733\n",
            "Epoch 51/100\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 4.5235\n",
            "Epoch 51: loss did not improve from 4.27328\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.3507\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - ETA: 0s - loss: 4.5075\n",
            "Epoch 52: loss did not improve from 4.27328\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 4.5075\n",
            "Epoch 53/100\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 4.5719\n",
            "Epoch 53: loss did not improve from 4.27328\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 4.3867\n",
            "Epoch 54/100\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 4.4653\n",
            "Epoch 54: loss did not improve from 4.27328\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 4.3073\n",
            "Epoch 55/100\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 4.2341\n",
            "Epoch 55: loss improved from 4.27328 to 4.07404, saving model to ckpts/epoch055_loss4.074.hdf5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 4.0740\n",
            "Epoch 56/100\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 4.4529\n",
            "Epoch 56: loss did not improve from 4.07404\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.3722\n",
            "Epoch 57/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 4.2874\n",
            "Epoch 57: loss did not improve from 4.07404\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.3154\n",
            "Epoch 58/100\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 4.6036\n",
            "Epoch 58: loss did not improve from 4.07404\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4504\n",
            "Epoch 59/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 4.6953\n",
            "Epoch 59: loss did not improve from 4.07404\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.5692\n",
            "Epoch 60/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 4.3416\n",
            "Epoch 60: loss did not improve from 4.07404\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.2196\n",
            "Epoch 61/100\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 4.4069\n",
            "Epoch 61: loss did not improve from 4.07404\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4026\n",
            "Epoch 62/100\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 4.5781\n",
            "Epoch 62: loss did not improve from 4.07404\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4559\n",
            "Epoch 63/100\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 4.5367\n",
            "Epoch 63: loss did not improve from 4.07404\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4124\n",
            "Epoch 64/100\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 4.5166\n",
            "Epoch 64: loss did not improve from 4.07404\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.4274\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - ETA: 0s - loss: 4.3756\n",
            "Epoch 65: loss did not improve from 4.07404\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.3756\n",
            "Epoch 65: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff326187790>"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the best weights file created by .fit()\n",
        "model = Model([in_a, in_p, in_n], triplet_loss_layer) \n",
        "model.load_weights(\"./weights.hdf5\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64NeJlFkcaDR",
        "outputId": "443c40d9-baa9-406e-f9e9-b748532735d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " song_a (InputLayer)            [(None, 11, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " song_p (InputLayer)            [(None, 11, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " song_n (InputLayer)            [(None, 11, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " Embedding (Functional)         (None, 11)           1540        ['song_a[0][0]',                 \n",
            "                                                                  'song_p[0][0]',                 \n",
            "                                                                  'song_n[0][0]']                 \n",
            "                                                                                                  \n",
            " triplet_loss_layer (TripletLos  ()                  0           ['Embedding[0][0]',              \n",
            " sLayer)                                                          'Embedding[1][0]',              \n",
            "                                                                  'Embedding[2][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,540\n",
            "Trainable params: 1,518\n",
            "Non-trainable params: 22\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bypass the triplet input layers (allows us to just input a single song)\n",
        "base_model = model.get_layer(\"Embedding\")\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "MkcBDplyc4KW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260d41ec-fb50-4de0-df3a-e7a84e3f078e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Embedding\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " song_a (InputLayer)         [(None, 11, 1)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 11, 11)            22        \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 121)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 11)                1342      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 11)               44        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 11)                132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,540\n",
            "Trainable params: 1,518\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "existing = set()\n",
        "spotify_features_dataset = []\n",
        "\n",
        "# read tracks & feature vectors from output.csv\n",
        "with open('/content/output.csv', 'r') as file:\n",
        "    next(file) # don't read in header\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "      if row[12] not in existing:\n",
        "        existing.add(row[12])\n",
        "        spotify_features_dataset.append((row[12], tuple([float(i) for i in row[:11]])))\n",
        "\n",
        "print(spotify_features_dataset[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRY2TJvp1lsx",
        "outputId": "0ccb69ca-32b2-4a6a-9012-02e6abcd568a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('5IbCV9Icebx8rR6wAp5hhP', (0.451, 0.258, 2.0, -15.947, 1.0, 0.0681, 0.763, 0.0, 0.136, 0.646, 78.62)), ('6rKVAvjHcxAzZ1BHtwh5yC', (0.588, 0.189, 0.0, -17.737, 1.0, 0.0451, 0.756, 0.0, 0.169, 0.904, 140.467)), ('6Jlkb1Wh08RYHstWScsTvg', (0.281, 0.0652, 6.0, -22.218, 1.0, 0.0388, 0.959, 9.75e-06, 0.102, 0.316, 77.442)), ('0XhC8bfStML9ygBmfOt1JJ', (0.746, 0.3, 8.0, -16.037, 1.0, 0.164, 0.682, 0.0, 0.39, 0.842, 130.248)), ('0ABxAcsRWlqckkyONsfP67', (0.493, 0.235, 7.0, -14.847, 1.0, 0.14, 0.732, 0.0, 0.126, 0.455, 81.576))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get embeddings (transformed feature vectors) for every song in output.csv\n",
        "lookup_table = {}\n",
        "\n",
        "track_ids = [tup[0] for tup in spotify_features_dataset]\n",
        "track_vectors = [tup[1] for tup in spotify_features_dataset]\n",
        "\n",
        "count = 0\n",
        "while count < len(track_vectors):\n",
        "  result = base_model.predict(track_vectors[count:count+1800])\n",
        "  for (id, vec) in zip(track_ids[count: count+1800], result):\n",
        "    lookup_table[id] = tuple(vec)\n",
        "  count += 1800"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y01hPt_03aWM",
        "outputId": "cd3b0a71-9502-4c55-d587-51b8d121ed66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 1ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 4ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "57/57 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save transformed track vectors to file\n",
        "\n",
        "f = open(\"transformed.txt\", \"w\")\n",
        "for key, value in lookup_table.items():\n",
        "  f.write(key.replace(\" \", \"\") + \" \" + str(value).replace(\" \", \"\") + \"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "weRqiMRNCt-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load transformed track vectors from \"transformed.txt\" file\n",
        "# lookup_table = {}\n",
        "\n",
        "# with open('/content/transformed.txt', 'r') as file:\n",
        "#   for line in file:\n",
        "#     arr = line.split(\" \")\n",
        "#     if len(arr) == 2:\n",
        "#       lookup_table[arr[0]] = ast.literal_eval(arr[1])"
      ],
      "metadata": {
        "id": "8ckizuTnDbF-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
